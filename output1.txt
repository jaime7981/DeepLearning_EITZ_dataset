vicentegana10@MacBook-Air-de-Vicente-4 DeepLearning_EITZ_dataset % /usr/local/bin/python3 /Users/vicentegana10/Documents/deep/DeepLearning_EITZ_dataset/assignment_1.py
loading mapping
loading train images
(256, 256, 3)
float32
185
loading test images
(128, 128, 3)
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 128, 128, 3)]        0         []                            
                                                                                                  
 conv1 (Conv2D)              (None, 128, 128, 32)         896       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 128, 128, 32)         128       ['conv1[0][0]']               
 Normalization)                                                                                   
                                                                                                  
 re_lu (ReLU)                multiple                     0         ['batch_normalization[0][0]', 
                                                                     'batch_normalization_1[0][0]'
                                                                    , 'batch_normalization_2[0][0]
                                                                    ',                            
                                                                     'embedding[0][0]']           
                                                                                                  
 max_pooling2d (MaxPooling2  multiple                     0         ['re_lu[0][0]',               
 D)                                                                  're_lu[1][0]',               
                                                                     're_lu[2][0]']               
                                                                                                  
 conv2 (Conv2D)              (None, 64, 64, 64)           18496     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_1 (Bat  (None, 64, 64, 64)           256       ['conv2[0][0]']               
 chNormalization)                                                                                 
                                                                                                  
 conv3 (Conv2D)              (None, 32, 32, 128)          73856     ['max_pooling2d[1][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 32, 32, 128)          512       ['conv3[0][0]']               
 chNormalization)                                                                                 
                                                                                                  
 flatten (Flatten)           (None, 32768)                0         ['max_pooling2d[2][0]']       
                                                                                                  
 dense1 (Dense)              (None, 256)                  8388864   ['flatten[0][0]']             
                                                                                                  
 embedding (BatchNormalizat  (None, 256)                  1024      ['dense1[0][0]']              
 ion)                                                                                             
                                                                                                  
 dense (Dense)               (None, 250)                  64250     ['re_lu[3][0]']               
                                                                                                  
 tf.nn.softmax (TFOpLambda)  (None, 250)                  0         ['dense[0][0]']               
                                                                                                  
==================================================================================================
Total params: 8548282 (32.61 MB)
Trainable params: 8547322 (32.61 MB)
Non-trainable params: 960 (3.75 KB)
__________________________________________________________________________________________________
Epoch 1/50
250/250 [==============================] - 239s 952ms/step - loss: 3.7337 - accuracy: 0.2630 - val_loss: 4.6215 - val_accuracy: 0.1240
Epoch 2/50
250/250 [==============================] - 233s 931ms/step - loss: 2.0685 - accuracy: 0.5523 - val_loss: 4.1485 - val_accuracy: 0.1762
Epoch 3/50
250/250 [==============================] - 250s 1s/step - loss: 1.1098 - accuracy: 0.7729 - val_loss: 4.3929 - val_accuracy: 0.1542
Epoch 4/50
250/250 [==============================] - 241s 961ms/step - loss: 0.3876 - accuracy: 0.9412 - val_loss: 3.2221 - val_accuracy: 0.3190
Epoch 5/50
250/250 [==============================] - 231s 923ms/step - loss: 0.0909 - accuracy: 0.9946 - val_loss: 2.9266 - val_accuracy: 0.3785
Epoch 6/50
250/250 [==============================] - 255s 1s/step - loss: 0.0269 - accuracy: 0.9994 - val_loss: 2.9334 - val_accuracy: 0.3865
Epoch 7/50
250/250 [==============================] - 233s 932ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.4963 - val_accuracy: 0.4600
Epoch 8/50
250/250 [==============================] - 236s 943ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.5095 - val_accuracy: 0.4565
Epoch 9/50
250/250 [==============================] - 235s 939ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.4332 - val_accuracy: 0.4735
Epoch 10/50
250/250 [==============================] - 232s 928ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.4613 - val_accuracy: 0.4733
Epoch 11/50
250/250 [==============================] - 235s 941ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.4140 - val_accuracy: 0.4843
Epoch 12/50
250/250 [==============================] - 235s 937ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.3798 - val_accuracy: 0.4925
Epoch 13/50
250/250 [==============================] - 234s 935ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.3680 - val_accuracy: 0.4947
Epoch 14/50
250/250 [==============================] - 239s 955ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.3486 - val_accuracy: 0.5008
Epoch 15/50
250/250 [==============================] - 247s 987ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.3286 - val_accuracy: 0.5052
Epoch 16/50
250/250 [==============================] - 241s 963ms/step - loss: 9.7222e-04 - accuracy: 1.0000 - val_loss: 2.3431 - val_accuracy: 0.5063
Epoch 17/50
250/250 [==============================] - 236s 942ms/step - loss: 8.0060e-04 - accuracy: 1.0000 - val_loss: 2.3441 - val_accuracy: 0.5077
Epoch 18/50
250/250 [==============================] - 236s 942ms/step - loss: 6.7243e-04 - accuracy: 1.0000 - val_loss: 2.3537 - val_accuracy: 0.5088
Epoch 19/50
250/250 [==============================] - 248s 992ms/step - loss: 5.5604e-04 - accuracy: 1.0000 - val_loss: 2.3513 - val_accuracy: 0.5098
Epoch 20/50
250/250 [==============================] - 261s 1s/step - loss: 4.7442e-04 - accuracy: 1.0000 - val_loss: 2.3605 - val_accuracy: 0.5085
Epoch 21/50
250/250 [==============================] - 243s 971ms/step - loss: 3.9946e-04 - accuracy: 1.0000 - val_loss: 2.3545 - val_accuracy: 0.5185
Epoch 22/50
250/250 [==============================] - 235s 938ms/step - loss: 3.3733e-04 - accuracy: 1.0000 - val_loss: 2.3635 - val_accuracy: 0.5160
Epoch 23/50
250/250 [==============================] - 240s 957ms/step - loss: 2.8883e-04 - accuracy: 1.0000 - val_loss: 2.3677 - val_accuracy: 0.5160
Epoch 24/50
250/250 [==============================] - 236s 945ms/step - loss: 2.4799e-04 - accuracy: 1.0000 - val_loss: 2.3990 - val_accuracy: 0.5142
Epoch 25/50
250/250 [==============================] - 174s 693ms/step - loss: 2.0958e-04 - accuracy: 1.0000 - val_loss: 2.4014 - val_accuracy: 0.5138
Epoch 26/50
250/250 [==============================] - 142s 569ms/step - loss: 1.8028e-04 - accuracy: 1.0000 - val_loss: 2.4089 - val_accuracy: 0.5113
Epoch 27/50
250/250 [==============================] - 154s 614ms/step - loss: 1.5399e-04 - accuracy: 1.0000 - val_loss: 2.4250 - val_accuracy: 0.5115
Epoch 28/50
250/250 [==============================] - 155s 621ms/step - loss: 1.3257e-04 - accuracy: 1.0000 - val_loss: 2.4249 - val_accuracy: 0.5145
Epoch 29/50
250/250 [==============================] - 153s 612ms/step - loss: 1.1434e-04 - accuracy: 1.0000 - val_loss: 2.4424 - val_accuracy: 0.5100
Epoch 30/50
250/250 [==============================] - 153s 611ms/step - loss: 9.8782e-05 - accuracy: 1.0000 - val_loss: 2.4349 - val_accuracy: 0.5148
Epoch 31/50
250/250 [==============================] - 158s 631ms/step - loss: 8.4489e-05 - accuracy: 1.0000 - val_loss: 2.4512 - val_accuracy: 0.5132
Epoch 32/50
250/250 [==============================] - 161s 645ms/step - loss: 7.3862e-05 - accuracy: 1.0000 - val_loss: 2.4655 - val_accuracy: 0.5138
Epoch 33/50
250/250 [==============================] - 174s 694ms/step - loss: 6.3698e-05 - accuracy: 1.0000 - val_loss: 2.4777 - val_accuracy: 0.5120
Epoch 34/50
250/250 [==============================] - 161s 642ms/step - loss: 5.4731e-05 - accuracy: 1.0000 - val_loss: 2.4909 - val_accuracy: 0.5100
Epoch 35/50
250/250 [==============================] - 160s 641ms/step - loss: 4.7869e-05 - accuracy: 1.0000 - val_loss: 2.4900 - val_accuracy: 0.5107
Epoch 36/50
250/250 [==============================] - 160s 640ms/step - loss: 4.0716e-05 - accuracy: 1.0000 - val_loss: 2.5097 - val_accuracy: 0.5113
Epoch 37/50
250/250 [==============================] - 161s 643ms/step - loss: 3.6082e-05 - accuracy: 1.0000 - val_loss: 2.5286 - val_accuracy: 0.5082
Epoch 38/50
250/250 [==============================] - 160s 641ms/step - loss: 3.1026e-05 - accuracy: 1.0000 - val_loss: 2.5319 - val_accuracy: 0.5075
Epoch 39/50
250/250 [==============================] - 161s 645ms/step - loss: 2.7024e-05 - accuracy: 1.0000 - val_loss: 2.5342 - val_accuracy: 0.5077
Epoch 40/50
250/250 [==============================] - 161s 644ms/step - loss: 2.3746e-05 - accuracy: 1.0000 - val_loss: 2.5583 - val_accuracy: 0.5065
Epoch 41/50
250/250 [==============================] - 161s 643ms/step - loss: 2.0717e-05 - accuracy: 1.0000 - val_loss: 2.5555 - val_accuracy: 0.5080
Epoch 42/50
250/250 [==============================] - 162s 649ms/step - loss: 1.7885e-05 - accuracy: 1.0000 - val_loss: 2.5818 - val_accuracy: 0.5042
Epoch 43/50
250/250 [==============================] - 165s 659ms/step - loss: 1.5424e-05 - accuracy: 1.0000 - val_loss: 2.5906 - val_accuracy: 0.5048
Epoch 44/50
250/250 [==============================] - 166s 663ms/step - loss: 1.3431e-05 - accuracy: 1.0000 - val_loss: 2.5818 - val_accuracy: 0.5075
Epoch 45/50
250/250 [==============================] - 161s 643ms/step - loss: 1.1642e-05 - accuracy: 1.0000 - val_loss: 2.5994 - val_accuracy: 0.5075
Epoch 46/50
250/250 [==============================] - 162s 647ms/step - loss: 1.0182e-05 - accuracy: 1.0000 - val_loss: 2.6221 - val_accuracy: 0.5050
Epoch 47/50
250/250 [==============================] - 959s 4s/step - loss: 8.9995e-06 - accuracy: 1.0000 - val_loss: 2.6232 - val_accuracy: 0.5085
Epoch 48/50
250/250 [==============================] - 303s 1s/step - loss: 7.8169e-06 - accuracy: 1.0000 - val_loss: 2.6422 - val_accuracy: 0.5030
Epoch 49/50
250/250 [==============================] - 142s 568ms/step - loss: 6.8689e-06 - accuracy: 1.0000 - val_loss: 2.6504 - val_accuracy: 0.5048
Epoch 50/50
250/250 [==============================] - 155s 618ms/step - loss: 5.8967e-06 - accuracy: 1.0000 - val_loss: 2.6599 - val_accuracy: 0.5045
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
2/2 [==============================] - 0s 70ms/step
2/2 [==============================] - 0s 76ms/step
2/2 [==============================] - 0s 71ms/step
2/2 [==============================] - 0s 71ms/step
2/2 [==============================] - 0s 72ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 74ms/step
2/2 [==============================] - 0s 72ms/step
2/2 [==============================] - 0s 72ms/step
2/2 [==============================] - 0s 72ms/step
2/2 [==============================] - 0s 72ms/step
2/2 [==============================] - 0s 74ms/step
2/2 [==============================] - 0s 76ms/step
2/2 [==============================] - 0s 74ms/step
2/2 [==============================] - 0s 72ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 72ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 72ms/step
2/2 [==============================] - 0s 72ms/step
2/2 [==============================] - 0s 72ms/step
2/2 [==============================] - 0s 72ms/step
2/2 [==============================] - 0s 74ms/step
2/2 [==============================] - 0s 75ms/step
2/2 [==============================] - 0s 75ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 78ms/step
2/2 [==============================] - 0s 72ms/step
2/2 [==============================] - 0s 72ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 74ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 77ms/step
2/2 [==============================] - 0s 72ms/step
2/2 [==============================] - 0s 72ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 80ms/step
2/2 [==============================] - 0s 74ms/step
2/2 [==============================] - 0s 74ms/step
2/2 [==============================] - 0s 72ms/step
2/2 [==============================] - 0s 74ms/step
2/2 [==============================] - 0s 74ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 76ms/step
2/2 [==============================] - 0s 74ms/step
2/2 [==============================] - 0s 74ms/step
2/2 [==============================] - 0s 74ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 74ms/step
2/2 [==============================] - 0s 79ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 75ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 73ms/step
2/2 [==============================] - 0s 72ms/step
2/2 [==============================] - 0s 80ms/step
1/1 [==============================] - 0s 82ms/step